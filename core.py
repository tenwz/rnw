from telegraph import TelegraphAPI, Page
import datetime
from urllib.parse import quote
import getpass
from typing import Optional, Generator, Dict
import json
import time

api = TelegraphAPI()

def create_account():
    return api.create_account(short_name=getpass.getuser(), author_name=getpass.getuser())

def generate_url(type_name: str, index: int) -> str:
    date = datetime.datetime.now(datetime.timezone.utc).strftime("%m-%d")
    suffix = f"-{index}" if index > 1 else ""
    return f"rnw{quote(type_name)}-{date}{suffix}"

def write(content: str, channel: Optional[str] = None):
    create_account()
    metadata = f"rnwpost{channel or ''}"
    page = api.create_page(
        author_name=getpass.getuser(),
        title=metadata, 
        content=[{"tag": "p", "children": [content]}], 
        return_content=True
    )
    print(f"Page created: {page['url']}")

def read(channel: Optional[str], index: int) -> Page:
    return api.get_page(generate_url(f"post{channel or ''}", index), True)

def find_total_posts(channel: Optional[str]) -> int:
    def valid(i):
        try: 
            api.get_page(generate_url(f"post{channel or ''}", i), True)
            return True
        except: 
            return False
    
    if not valid(1): 
        return 0
    
    # æŒ‡æ•°æœç´¢ + äºŒåˆ†æœç´¢
    guess = 16
    if valid(guess):
        low, high = guess, guess * 2
        while valid(high): 
            low, high = high, high * 2
        left, right = low + 1, high
    else:
        left, right = 2, guess
    
    while left < right:
        mid = (left + right) // 2
        if valid(mid): 
            left = mid + 1
        else: 
            right = mid
    return left - 1

def read_cache(channel: Optional[str], start: int, end: int):
    url = generate_url(f"list{channel or ''}-{start}-{end}", 1)
    page = api.get_page(url, True)
    
    # å°è¯•ä»contentæˆ–descriptionè·å–JSONæ•°æ®
    for field in ["content", "description"]:
        if page.get(field):
            try:
                data = page[field][0]["children"][0] if field == "content" else page[field]
                return json.loads(data)
            except: 
                continue
    return []

def save_cache(channel: Optional[str], start: int, end: int, posts: list):
    create_account()
    metadata = f"rnwlist{channel or ''}-{start}-{end}"
    api.create_page(
        title=metadata, 
        content=[{"tag": "p", "children": [json.dumps(posts)]}], 
        return_content=True
    )

def readlist_stream(channel: Optional[str], pageNo: int = 1, pageSize: int = 10) -> Generator[Dict, None, None]:
    """æµå¼è¯»å–æ¶ˆæ¯åˆ—è¡¨ï¼Œé€æ¡è¿”å›æ¶ˆæ¯"""
    total = find_total_posts(channel)
    end = total - (pageNo - 1) * pageSize
    start = max(1, end - pageSize + 1)
    
    if end <= 0:
        return
    
    # é¦–å…ˆå°è¯•ä»ç¼“å­˜è·å–
    try:
        cached_posts = read_cache(channel, start, end)
        if cached_posts:
            # å¦‚æœæœ‰ç¼“å­˜ï¼Œå¿«é€Ÿè¿”å›æ‰€æœ‰æ¶ˆæ¯
            for post in cached_posts:
                yield post
            return
    except:
        pass
    
    # ç¼“å­˜æœªå‘½ä¸­ï¼Œé€æ¡è¯»å–å¹¶æµå¼è¿”å›
    posts = []
    for i in range(end, start - 1, -1):
        try:
            post = read(channel, i)
            if post.get("description"):
                post_data = {
                    "name": post.get("author_name", "Anonymous"), 
                    "content": post["description"]
                }
                posts.append(post_data)
                
                # ç«‹å³è¿”å›è¿™æ¡æ¶ˆæ¯
                yield post_data
                
                # æ·»åŠ å°å»¶è¿Ÿï¼Œè®©ç”¨æˆ·çœ‹åˆ°æµå¼æ•ˆæœ
                time.sleep(0.1)
                
        except Exception as e:
            # è¯»å–å¤±è´¥æ—¶ç»§ç»­å¤„ç†ä¸‹ä¸€æ¡
            continue
    
    # æ‰€æœ‰æ¶ˆæ¯è¯»å–å®Œæˆåï¼Œå¼‚æ­¥ä¿å­˜ç¼“å­˜
    if posts:
        try:
            save_cache(channel, start, end, posts)
        except Exception as e:
            # ç¼“å­˜ä¿å­˜å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
            pass

def readlist(channel: Optional[str], pageNo: int = 1, pageSize: int = 10):
    """å…¼å®¹æ€§å‡½æ•°ï¼Œè¿”å›å®Œæ•´åˆ—è¡¨"""
    return list(readlist_stream(channel, pageNo, pageSize))

# æ‰¹é‡é¢„åŠ è½½å‡½æ•°ï¼Œç”¨äºæå‡æ€§èƒ½
def preload_posts(channel: Optional[str], start_page: int = 1, end_page: int = 3):
    """é¢„åŠ è½½å¤šé¡µæ•°æ®åˆ°ç¼“å­˜"""
    import threading
    
    def preload_worker(page_no):
        try:
            list(readlist_stream(channel, page_no, 10))
        except:
            pass
    
    threads = []
    for page_no in range(start_page, end_page + 1):
        thread = threading.Thread(target=preload_worker, args=(page_no,))
        thread.daemon = True
        thread.start()
        threads.append(thread)
    
    return threads

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    write("HelloWord")
    
    print("Stream loading messages...")
    for post in readlist_stream(pageNo=1, pageSize=10):
        print(f"ğŸ“¨ {post['name']}: {post['content']}")
        print("â”€" * 50)